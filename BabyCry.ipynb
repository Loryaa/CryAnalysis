{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in e:\\programs\\python 3.11.5\\lib\\site-packages (2.13.1)\n",
            "Requirement already satisfied: tensorflow-intel==2.13.1 in e:\\programs\\python 3.11.5\\lib\\site-packages (from tensorflow) (2.13.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in e:\\programs\\python 3.11.5\\lib\\site-packages (from tensorflow-intel==2.13.1->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in e:\\programs\\python 3.11.5\\lib\\site-packages (from tensorflow-intel==2.13.1->tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in e:\\programs\\python 3.11.5\\lib\\site-packages (from tensorflow-intel==2.13.1->tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in e:\\programs\\python 3.11.5\\lib\\site-packages (from tensorflow-intel==2.13.1->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in e:\\programs\\python 3.11.5\\lib\\site-packages (from tensorflow-intel==2.13.1->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in e:\\programs\\python 3.11.5\\lib\\site-packages (from tensorflow-intel==2.13.1->tensorflow) (3.10.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in e:\\programs\\python 3.11.5\\lib\\site-packages (from tensorflow-intel==2.13.1->tensorflow) (16.0.6)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in e:\\programs\\python 3.11.5\\lib\\site-packages (from tensorflow-intel==2.13.1->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in e:\\programs\\python 3.11.5\\lib\\site-packages (from tensorflow-intel==2.13.1->tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in e:\\programs\\python 3.11.5\\lib\\site-packages (from tensorflow-intel==2.13.1->tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in e:\\programs\\python 3.11.5\\lib\\site-packages (from tensorflow-intel==2.13.1->tensorflow) (4.25.0)\n",
            "Requirement already satisfied: setuptools in e:\\programs\\python 3.11.5\\lib\\site-packages (from tensorflow-intel==2.13.1->tensorflow) (65.5.0)\n",
            "Requirement already satisfied: six>=1.12.0 in e:\\programs\\python 3.11.5\\lib\\site-packages (from tensorflow-intel==2.13.1->tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in e:\\programs\\python 3.11.5\\lib\\site-packages (from tensorflow-intel==2.13.1->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in e:\\programs\\python 3.11.5\\lib\\site-packages (from tensorflow-intel==2.13.1->tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in e:\\programs\\python 3.11.5\\lib\\site-packages (from tensorflow-intel==2.13.1->tensorflow) (1.15.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in e:\\programs\\python 3.11.5\\lib\\site-packages (from tensorflow-intel==2.13.1->tensorflow) (1.59.2)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in e:\\programs\\python 3.11.5\\lib\\site-packages (from tensorflow-intel==2.13.1->tensorflow) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in e:\\programs\\python 3.11.5\\lib\\site-packages (from tensorflow-intel==2.13.1->tensorflow) (2.13.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in e:\\programs\\python 3.11.5\\lib\\site-packages (from tensorflow-intel==2.13.1->tensorflow) (2.13.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in e:\\programs\\python 3.11.5\\lib\\site-packages (from tensorflow-intel==2.13.1->tensorflow) (0.31.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in e:\\programs\\python 3.11.5\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.1->tensorflow) (0.41.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in e:\\programs\\python 3.11.5\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow) (2.23.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in e:\\programs\\python 3.11.5\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in e:\\programs\\python 3.11.5\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in e:\\programs\\python 3.11.5\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in e:\\programs\\python 3.11.5\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in e:\\programs\\python 3.11.5\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in e:\\programs\\python 3.11.5\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in e:\\programs\\python 3.11.5\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in e:\\programs\\python 3.11.5\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in e:\\programs\\python 3.11.5\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\programs\\python 3.11.5\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in e:\\programs\\python 3.11.5\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\programs\\python 3.11.5\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in e:\\programs\\python 3.11.5\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in e:\\programs\\python 3.11.5\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in e:\\programs\\python 3.11.5\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in e:\\programs\\python 3.11.5\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.1->tensorflow) (3.2.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "W-A7-OtL7s-9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "import pickle\n",
        "import tensorflow as tp\n",
        "from collections import Counter\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "47ziMC1A704O"
      },
      "outputs": [],
      "source": [
        "# Define raw audio dictionary\n",
        "raw_audio = {}\n",
        "\n",
        "# Loop through directories and label audio files\n",
        "directories = ['hungry', 'belly_pain', 'burping', 'discomfort', 'tired']\n",
        "for directory in directories:\n",
        "    path = 'C:/Users/Gem/Documents/research streamlit/donateacry_corpus_cleaned_and_updated_data/' + directory\n",
        "    for filename in os.listdir(path):\n",
        "        if filename.endswith(\".wav\"):\n",
        "            raw_audio[os.path.join(path, filename)] = directory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4q6AEkNK8EKE"
      },
      "outputs": [],
      "source": [
        "# Define function to extract MFCC features and chop audio\n",
        "def extract_mfcc(audio_file, max_length=100):\n",
        "    audiofile, sr = librosa.load(audio_file)\n",
        "    fingerprint = librosa.feature.mfcc(y=audiofile, sr=sr, n_mfcc=20)\n",
        "    if fingerprint.shape[1] < max_length:\n",
        "        pad_width = max_length - fingerprint.shape[1]\n",
        "        fingerprint_padded = np.pad(fingerprint, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "        return fingerprint_padded.T\n",
        "    elif fingerprint.shape[1] > max_length:\n",
        "        return fingerprint[:, :max_length].T\n",
        "    else:\n",
        "        return fingerprint.T\n",
        "\n",
        "# Chop audio and extract MFCC features for each track\n",
        "X = []\n",
        "y = []\n",
        "max_length = 100\n",
        "for i, (audio_file, label) in enumerate(raw_audio.items()):\n",
        "    mfcc_features = extract_mfcc(audio_file, max_length=max_length)\n",
        "    X.append(mfcc_features)\n",
        "    y.append(label)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_eXJ6Pf18Nnf"
      },
      "outputs": [],
      "source": [
        "# Convert lists to numpy arrays\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Flatten the features and labels\n",
        "X_flat = X.reshape(X.shape[0], -1)\n",
        "y_flat = y\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_flat, y_flat, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6cbk_h4P8Wm2"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Train and evaluate models\n",
        "models = [\n",
        "    ('Random Forest', RandomForestClassifier(n_estimators=25, max_features=5)),\n",
        "    ('Logistic Regression', LogisticRegression()),\n",
        "    ('Decision Tree', DecisionTreeClassifier()),\n",
        "    ('SVM', SVC()),\n",
        "]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFSjIisU-Bj9",
        "outputId": "47c919ef-bc9c-4fc3-ea77-42d3e8e2fe07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model, Accuracy, Precision, Recall\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "e:\\Programs\\Python 3.11.5\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest: 0.7934782608695652, 0.6296077504725898, 0.7934782608695652\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "e:\\Programs\\Python 3.11.5\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression: 0.6413043478260869, 0.6159897025171625, 0.6413043478260869\n",
            "Decision Tree: 0.6413043478260869, 0.6413043478260869, 0.6413043478260869\n",
            "SVM: 0.7934782608695652, 0.6296077504725898, 0.7934782608695652\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "e:\\Programs\\Python 3.11.5\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "print(\"Model, Accuracy, Precision, Recall\")\n",
        "for model_name, model in models:\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    print(f\"{model_name}: {accuracy}, {precision}, {recall}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdH0N-idBi08",
        "outputId": "705c7a0a-b8ea-4b5f-f8c9-2f452660490c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(364, 2000)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-BdnDwr_c1N",
        "outputId": "a2719b9f-6cf7-4757-a3ce-1cd3bf01311b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 7s 229ms/step - loss: 1.1835 - accuracy: 0.6151 - val_loss: 0.6610 - val_accuracy: 0.8630\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 1s 67ms/step - loss: 0.7258 - accuracy: 0.8454 - val_loss: 0.6012 - val_accuracy: 0.8630\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 1s 67ms/step - loss: 0.6702 - accuracy: 0.8454 - val_loss: 0.6117 - val_accuracy: 0.8630\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 1s 67ms/step - loss: 0.6714 - accuracy: 0.8454 - val_loss: 0.6193 - val_accuracy: 0.8630\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 1s 65ms/step - loss: 0.6410 - accuracy: 0.8454 - val_loss: 0.6201 - val_accuracy: 0.8630\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 1s 68ms/step - loss: 0.6469 - accuracy: 0.8454 - val_loss: 0.6163 - val_accuracy: 0.8630\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 1s 67ms/step - loss: 0.6383 - accuracy: 0.8454 - val_loss: 0.6107 - val_accuracy: 0.8630\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 1s 67ms/step - loss: 0.6109 - accuracy: 0.8454 - val_loss: 0.6097 - val_accuracy: 0.8630\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 1s 67ms/step - loss: 0.5850 - accuracy: 0.8454 - val_loss: 0.5974 - val_accuracy: 0.8630\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 1s 65ms/step - loss: 0.5790 - accuracy: 0.8454 - val_loss: 0.6009 - val_accuracy: 0.8630\n",
            "3/3 [==============================] - 1s 69ms/step - loss: 0.8722 - accuracy: 0.7935\n",
            "Accuracy: 0.79347825050354\n",
            "3/3 [==============================] - 1s 22ms/step\n",
            "Precision: 0.6296077504725898\n",
            "Recall: 0.7934782608695652\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "e:\\Programs\\Python 3.11.5\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# Reshape data for LSTM input\n",
        "n_samples, n_features = X_train.shape[0], X_train.shape[1] // 100\n",
        "n_timesteps = 100\n",
        "X_train_lstm = X_train.reshape((n_samples, 100, 20))\n",
        "n_samples_test = X_test.shape[0]\n",
        "X_test_lstm = X_test.reshape((n_samples_test, n_timesteps, n_features))\n",
        "\n",
        "# Convert labels to numeric values\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# Define LSTM model\n",
        "lstm_model = Sequential([\n",
        "    LSTM(units=128, input_shape=(n_timesteps, n_features)),\n",
        "    Dropout(0.2),\n",
        "    Dense(units=64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(units=len(np.unique(y_train_encoded)), activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "# Compile LSTM model\n",
        "lstm_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train LSTM model\n",
        "lstm_model.fit(X_train_lstm, y_train_encoded, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate LSTM model\n",
        "_, accuracy = lstm_model.evaluate(X_test_lstm, y_test_encoded)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "# Predict probabilities for the test dataset using the trained LSTM model\n",
        "predicted_probabilities = lstm_model.predict(X_test_lstm)\n",
        "\n",
        "# Convert probabilities to class labels\n",
        "predicted_labels = np.argmax(predicted_probabilities, axis=1)\n",
        "\n",
        "# Calculate precision\n",
        "precision = precision_score(y_test_encoded, predicted_labels, average='weighted')\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(y_test_encoded, predicted_labels, average='weighted')\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4Ll8k9I0NzE",
        "outputId": "2643baa9-190d-49bf-fd2e-7ae05549ed23"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['lstm_audio_model.joblib']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(lstm_model, \"lstm_audio_model.joblib\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "yhf5-K372ez0"
      },
      "outputs": [],
      "source": [
        "def pickle_model(model, modelname):\n",
        "    directory = 'models'\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "    with open(os.path.join(directory, str(modelname) + '.pkl'), 'wb') as f:\n",
        "        return pickle.dump(model, f)\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "pickle_model(model, \"myRandomForest\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vJC2hBXJogh8"
      },
      "outputs": [],
      "source": [
        "def getModel(pickle_path):\n",
        "  with open(pickle_path, 'rb') as f:\n",
        "        return pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "c_yqM-jEoXn4"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "model_path = \"models/myRandomForest.pkl\"  # Replace with your model path\n",
        "with open(model_path, \"rb\") as f:\n",
        "    model = joblib.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypgf53c-1zGb",
        "outputId": "85b54901-d73a-4338-ec9a-edac677c9132"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydub in e:\\programs\\python 3.11.5\\lib\\site-packages (0.25.1)\n"
          ]
        }
      ],
      "source": [
        "pip install pydub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pur_4ZQw8kT2",
        "outputId": "85af8245-729c-4ab2-fbe6-c13fb80c82f3"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'hungry baby.mp3'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[16], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;66;03m# Example of reading audio data from a file-like object (e.g., uploaded file)\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhungry baby.mp3\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     39\u001b[0m         mp3_data \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     41\u001b[0m     audio \u001b[38;5;241m=\u001b[39m AudioSegment\u001b[38;5;241m.\u001b[39mfrom_mp3(BytesIO(mp3_data))\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'hungry baby.mp3'"
          ]
        }
      ],
      "source": [
        "from io import BytesIO\n",
        "from pydub import AudioSegment\n",
        "import wave\n",
        "import math\n",
        "import os\n",
        "import uuid\n",
        "\n",
        "# Define the function to chop the audio\n",
        "def chop_new_audio(audio_data, folder):\n",
        "    os.makedirs(folder, exist_ok=True)  # Create directory if it doesn't exist\n",
        "    audio = wave.open(audio_data, 'rb')\n",
        "    frame_rate = audio.getframerate()\n",
        "    n_frames = audio.getnframes()\n",
        "    window_size = 2 * frame_rate\n",
        "    num_secs = int(math.ceil(n_frames / frame_rate))\n",
        "    last_number_frames = 0\n",
        "    for i in range(num_secs):\n",
        "        shortfilename = str(uuid.uuid4())  # Generate a unique filename\n",
        "        snippetfilename = f\"{folder}/{shortfilename}snippet{i+1}.wav\"\n",
        "        snippet = wave.open(snippetfilename, 'wb')\n",
        "        snippet.setnchannels(2)\n",
        "        snippet.setsampwidth(audio.getsampwidth())\n",
        "        snippet.setframerate(frame_rate)\n",
        "        snippet.setnframes(audio.getnframes())\n",
        "        snippet.writeframes(audio.readframes(window_size))\n",
        "        audio.setpos(audio.tell() - 1 * frame_rate)\n",
        "\n",
        "         # Check if the frame size of the snippet matches the previous snippets\n",
        "        if last_number_frames < 1:\n",
        "            last_number_frames = snippet.getnframes()\n",
        "        elif snippet.getnframes() != last_number_frames:\n",
        "            os.rename(snippetfilename, f\"{snippetfilename}.bak\")\n",
        "        snippet.close()\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Example of reading audio data from a file-like object (e.g., uploaded file)\n",
        "    with open('hungry baby.mp3', 'rb') as f:\n",
        "        mp3_data = f.read()\n",
        "\n",
        "    audio = AudioSegment.from_mp3(BytesIO(mp3_data))\n",
        "    wav_data = BytesIO()\n",
        "    audio.export(wav_data, format=\"wav\")\n",
        "    wav_data.seek(0)\n",
        "\n",
        "    folder_name = \"samples\"\n",
        "    chop_new_audio(wav_data, folder_name)\n",
        "    print(\"Audio chopped successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uc22mK_i8r4m",
        "outputId": "894752d7-31e3-490f-8eae-f7b90aef0e88"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[WinError 3] The system cannot find the path specified: 'samples/'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[17], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      4\u001b[0m folder_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msamples/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      8\u001b[0m         audiofile, sr \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, filename))\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'samples/'"
          ]
        }
      ],
      "source": [
        "# Predict on new audio snippets\n",
        "predictions = []\n",
        "\n",
        "folder_path = 'samples/'\n",
        "\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audiofile, sr = librosa.load(os.path.join(folder_path, filename))\n",
        "        fingerprint = librosa.feature.mfcc(y=audiofile, sr=sr, n_mfcc=20)\n",
        "        fingerprint_flat = fingerprint.reshape(-1)  # Flatten the MFCC features\n",
        "        # Pad or truncate features to match the number of features used for training\n",
        "        if len(fingerprint_flat) < 2000:\n",
        "            fingerprint_flat = np.pad(fingerprint_flat, (0, 2000 - len(fingerprint_flat)))\n",
        "        elif len(fingerprint_flat) > 2000:\n",
        "            fingerprint_flat = fingerprint_flat[:2000]\n",
        "        prediction = model.predict([fingerprint_flat])  # Reshape to match expected input format\n",
        "        predictions.append(prediction[0])\n",
        "\n",
        "from collections import Counter\n",
        "data = Counter(predictions)\n",
        "print(data.most_common())  # Returns all unique items and their counts\n",
        "print(data.most_common(1))  # Returns the most common prediction\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
